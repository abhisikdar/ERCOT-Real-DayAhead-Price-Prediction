{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RealTime+PartialInfo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Laju3VFeKkk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error,  mean_absolute_percentage_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown #download link"
      ],
      "metadata": {
        "id": "XNr7ohj1ePxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets load the data\n",
        "df = pd.read_excel('/content/Test Project Ercot.xlsx',sheet_name='DataSet')"
      ],
      "metadata": {
        "id": "dpZPY0xVeRMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets remove some redundant features\n",
        "df.drop('MARKETDAY',axis=1,inplace=True) #Already captured\n",
        "df.drop('MONTH',axis=1,inplace=True)     #Already captured\n",
        "df.drop('PEAKTYPE',axis=1,inplace=True)  #Empty\n",
        "df.drop('DATETIME',axis=1,inplace=True)  #Already captured\n",
        "df.drop('YEAR',axis=1,inplace=True)      #No point taking this as a feature\n",
        "\n",
        "df.dropna(axis=0,how='any',inplace=True) #Dropping rows with NA values"
      ],
      "metadata": {
        "id": "h6OueLnPeRKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_real=df[['HB_NORTH (RTLMP)']]\n",
        "y_ahead=df[['HB_NORTH (DALMP)']]\n",
        "X=df.drop(['HB_HOUSTON (RTLMP)','HB_NORTH (RTLMP)','HB_PAN (RTLMP)','HB_SOUTH (RTLMP)','HB_WEST (RTLMP)',\n",
        "           'HB_HOUSTON (DALMP)','HB_NORTH (DALMP)','HB_PAN (DALMP)','HB_SOUTH (DALMP)','HB_WEST (DALMP)'],axis=1) # 47+ 3 vars\n",
        "lst = ['WZ_West (RTLOAD)','WZ_Southern (RTLOAD)','WZ_SouthCentral (RTLOAD)',\n",
        "       'WZ_NorthCentral (RTLOAD)','WZ_North (RTLOAD)','WZ_Coast (RTLOAD)',\n",
        "       'WZ_ERCOT (RTLOAD)','WZ_East (RTLOAD)','WZ_FarWest (RTLOAD)',\n",
        "        'GR_COASTAL (WIND_RTI)','GR_ERCOT (WIND_RTI)','GR_NORTH (WIND_RTI)',\n",
        "        'GR_PANHANDLE (WIND_RTI)','GR_SOUTH (WIND_RTI)','GR_WEST (WIND_RTI)',\n",
        "        'ERCOT (GENERATION_SOLAR_RT)','ERCOT (AGG_DAM_ENERGY_SOLD)','ERCOT (AGG_DAM_ENERGY_BOUGHT)',\n",
        "        'ERCOT (HSL_DA)','ERCOT (HSL_CD)','ERCOT (PHYS_RESP_CAP)','ERCOT (RT_OR_PRADDER)',\n",
        "        'ERCOT (RT_ORD_PRADDER)']\n",
        "X_future = X.drop(lst,axis=1).    #24 +3 vars\n",
        "past_list = list(X_future.columns)\n",
        "past_list.remove('day')\n",
        "past_list.remove('month')\n",
        "past_list.remove('HOURENDING')\n",
        "X_past = X.drop(past_list,axis=1) #23 +3 vars"
      ],
      "metadata": {
        "id": "7x3tMoqZeRHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.values.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64eUBA26Kwdn",
        "outputId": "0678e654-79e8-45ca-d265-9fb1fd92792d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4218, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_y_DA,sc_y_real, sc_fut, sc_past, sc_all = StandardScaler(), StandardScaler(), StandardScaler(), StandardScaler(), StandardScaler()\n",
        "X_future = pd.DataFrame(sc_fut.fit_transform(X_future),index=X_future.index,columns=X_future.columns)\n",
        "X_past = pd.DataFrame(sc_past.fit_transform(X_past),index=X_past.index,columns=X_past.columns)\n",
        "y_ahead = pd.DataFrame(sc_y_DA.fit_transform(y_ahead),index=y_ahead.index,columns=y_ahead.columns)\n",
        "y_real = pd.DataFrame(sc_y_real.fit_transform(y_real),index=y_real.index,columns=y_real.columns)\n",
        "X = pd.DataFrame(sc_all.fit_transform(X),index=X.index,columns=X.columns)"
      ],
      "metadata": {
        "id": "qedWnP-Ee7r2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NN and utils"
      ],
      "metadata": {
        "id": "qxEhNKoAkMAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dev=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "months=[10,11,12,1,2,3]\n",
        "months_scaled = X_future['month'].unique().tolist()\n",
        "\n",
        "months_name=['Oct','Nov','Dec','Jan','Feb','Mar']\n",
        "target_months_name=['Jan','Feb','Mar']"
      ],
      "metadata": {
        "id": "3liw-Rnwjttq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateNN(months,X_full, X, y, y_scaled=False,scaler=None,aug=False,X_original=None,y_original=None,do_return=False,backtest=True,unfreeze=False):\n",
        "    if y_scaled:\n",
        "        assert scaler is not None\n",
        "    if aug:\n",
        "        assert X_original is not None\n",
        "        assert y_original is not None\n",
        "        \n",
        "    MSE_train=[]\n",
        "    MSE_test=[]\n",
        "    MAE_train=[]\n",
        "    MAE_test=[]\n",
        "\n",
        "    MAE_pretrain_train=[]\n",
        "    MSE_pretrain_train=[]\n",
        "    \n",
        "    target_months = months[3:]\n",
        "\n",
        "    if backtest:\n",
        "        y_pred_final=[]\n",
        "        for i,month in enumerate(target_months):\n",
        "            network = MyDNN(50,27)\n",
        "            network=network.to(dev)\n",
        "            trainer = MyDNNTrain(network)\n",
        "\n",
        "            ind_test = X.index[(X['month']==month)].tolist()\n",
        "            ind_train = X.index[(X['month']<month) | (X['month']>=0)].tolist()\n",
        "        \n",
        "            X_train, X_test, y_train, y_test = np.array(X.loc[ind_train]), np.array(X.loc[ind_test]), np.array(y.loc[ind_train]), np.array(y.loc[ind_test])\n",
        "\n",
        "            X_full_train = np.array(X_full.loc[ind_train])\n",
        "\n",
        "            if aug:\n",
        "                ind_original_test = X_original.index[(X_original['month']==month)].tolist()\n",
        "                X_test = np.array(X_original.loc[ind_original_test])\n",
        "                y_test = np.array(y_original.loc[ind_original_test])\n",
        "\n",
        "            #pretraining\n",
        "            network.pretrain = True\n",
        "            trainer.train(y_train,X_full_train)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                y_pred_train = network.predict(X_full_train)\n",
        "                if y_scaled:\n",
        "                    y_pred_train = scaler.inverse_transform(y_pred_train)\n",
        "\n",
        "                MSE_pretrain_train.append(round(mean_squared_error(y_pred_train,scaler.inverse_transform(y_train)),2))\n",
        "                MAE_pretrain_train.append(round(mean_absolute_error(y_pred_train,scaler.inverse_transform(y_train)),2))\n",
        "            \n",
        "            #finetuning\n",
        "            if unfreeze is True:\n",
        "                network.unfreeze=True\n",
        "            network.pretrain=False\n",
        "            trainer.train(y_train,X_train)\n",
        "                \n",
        "            with torch.no_grad():\n",
        "                y_pred_train= network.predict(X_train)\n",
        "                y_pred = network.predict(X_test)\n",
        "                    \n",
        "                    \n",
        "                if y_scaled:\n",
        "                    y_train=scaler.inverse_transform(y_train)\n",
        "                    y_test = scaler.inverse_transform(y_test)\n",
        "                    y_pred_train = scaler.inverse_transform(y_pred_train)\n",
        "                    y_pred = scaler.inverse_transform(y_pred)\n",
        "                        \n",
        "                        \n",
        "                MSE_train.append(round(mean_squared_error(y_train,y_pred_train),2))\n",
        "                MAE_train.append(round(mean_absolute_error(y_train,y_pred_train),2))\n",
        "                MSE_test.append(round(mean_squared_error(y_test,y_pred),2))\n",
        "                MAE_test.append(round(mean_absolute_error(y_test,y_pred),2))\n",
        "            \n",
        "            y_pred_final.append(y_pred)\n",
        "        \n",
        "    # plt.plot(months_name,MSE_train,label='MSE train')\n",
        "    # plt.plot(months_name,MAE_train,label='MAE train')\n",
        "    # plt.plot(months_name,MSE_test,label='MSE test')\n",
        "    # plt.plot(months_name,MAE_test,label='MAE test')\n",
        "    # plt.legend()\n",
        "    # plt.show()\n",
        "    print('MSE_train FT',MSE_train, 'avg:', round(sum(MSE_train)/len(MSE_train),2))\n",
        "    print('MSE_test FT',MSE_test,'avg:', round(sum(MSE_test)/len(MSE_train),2))\n",
        "    print('MAE_train FT',MAE_train,'avg:', round(sum(MAE_train)/len(MSE_train),2))\n",
        "    print('MAE_test FT',MAE_test,'avg:', round(sum(MAE_test)/len(MSE_train),2))\n",
        "    print('MSE_pretrain_train PT',MSE_pretrain_train, 'avg:', round(sum(MSE_pretrain_train)/len(MSE_pretrain_train),2))\n",
        "    print('MAE_pretrain_train PT',MAE_pretrain_train, 'avg:', round(sum(MAE_pretrain_train)/len(MAE_pretrain_train),2))\n",
        "\n",
        "    if do_return:\n",
        "        if backtest is False:\n",
        "            return y_pred\n",
        "        else:\n",
        "            return np.concatenate(y_pred_final,axis=0)"
      ],
      "metadata": {
        "id": "zzbhc_--j_T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, labels, features):\n",
        "        super(MyDataset, self).__init__()\n",
        "        self.labels = labels\n",
        "        self.features = features\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.features.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        feature = self.features[idx]\n",
        "        label = self.labels[idx]\n",
        "        return {'feature': feature, 'label': label}\n",
        "\n",
        "class MyDNN(nn.Module):\n",
        "    def __init__(self, pretrain_inp, train_inp, pretrain=False):\n",
        "        super(MyDNN, self).__init__()\n",
        "\n",
        "        self.fc_m1 = nn.Linear(pretrain_inp,100)\n",
        "        self.fc_m2 = nn.Linear(100, 50)\n",
        "        self.fc_m3 = nn.Linear(50, 25)\n",
        "        self.fc_m4 = nn.Linear(25, 1)\n",
        "\n",
        "\n",
        "        self.fc_p1 = nn.Linear(train_inp,70)\n",
        "        self.fc_p2 = nn.Linear(70,40)\n",
        "        self.fc_p3 = nn.Linear(40,23)\n",
        "\n",
        "        self.pretrain = pretrain\n",
        "        self.unfreeze = False\n",
        "    \n",
        "    def switch(self,signal):\n",
        "        self.fc_m1.weight.requires_grad = signal\n",
        "        self.fc_m2.weight.requires_grad = signal\n",
        "        self.fc_m3.weight.requires_grad = signal\n",
        "        self.fc_m4.weight.requires_grad = signal\n",
        "        self.fc_m1.bias.requires_grad = signal\n",
        "        self.fc_m2.bias.requires_grad = signal\n",
        "        self.fc_m3.bias.requires_grad = signal\n",
        "        self.fc_m4.bias.requires_grad = signal\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.pretrain:\n",
        "            self.switch(True)\n",
        "            x = F.relu(self.fc_m1(x))\n",
        "            x = F.relu(self.fc_m2(x))\n",
        "            x = F.relu(self.fc_m3(x))\n",
        "            x = self.fc_m4(x)\n",
        "            return x\n",
        "        else:\n",
        "            self.switch(self.unfreeze)\n",
        "            x1 = F.relu(self.fc_p1(x))\n",
        "            x1 = F.relu(self.fc_p2(x1))\n",
        "            x1 = self.fc_p3(x1)\n",
        "            \n",
        "            inp = torch.cat((x,x1),dim=1)\n",
        "\n",
        "            inp = F.relu(self.fc_m1(inp))\n",
        "            inp = F.relu(self.fc_m2(inp))\n",
        "            inp = F.relu(self.fc_m3(inp))\n",
        "            inp = self.fc_m4(inp)\n",
        "            return inp\n",
        "\n",
        "    def predict(self, features):\n",
        "        self.eval()\t\n",
        "        features = torch.from_numpy(features).float().to(dev)\n",
        "        return self.forward(features).detach().to('cpu').numpy()\n",
        "\n",
        "class MyDNNTrain(object): \n",
        "    def __init__(self, network):\n",
        "        self.network = network\n",
        "        self.learning_rate = .0001\n",
        "        self.optimizer = torch.optim.Adam(self.network.parameters(), lr=self.learning_rate,weight_decay=1e-6)\n",
        "        self.criterion = nn.MSELoss()\n",
        "        self.num_epochs = 200\n",
        "        self.batchsize = 100\n",
        "        self.shuffle = True\n",
        "        self.dev=dev\n",
        "\n",
        "    def train(self, labels, features):\n",
        "        self.network.train()\n",
        "        dataset = MyDataset(labels, features)\n",
        "        loader = DataLoader(dataset, shuffle=self.shuffle, batch_size = self.batchsize)\n",
        "        for epoch in range(self.num_epochs):\n",
        "            self.train_epoch(loader, epoch)\n",
        "\n",
        "    def train_epoch(self, loader, epoch):\n",
        "        total_loss = 0.0\n",
        "        for i, data in enumerate(loader):\n",
        "            features = data['feature'].float().to(dev)\n",
        "            labels = data['label'].float().to(dev)\n",
        "            self.optimizer.zero_grad()\n",
        "            predictions = self.network(features)\n",
        "            loss = self.criterion(predictions, labels)\n",
        "            loss.backward()\n",
        "            total_loss += loss.item()\n",
        "            self.optimizer.step()\n",
        "        #print( 'Epoch',epoch,'loss', total_loss/i)"
      ],
      "metadata": {
        "id": "ZqAimbPee7pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xnp = np.array(X)\n",
        "n = Xnp.shape[0]\n",
        "D=Xnp.shape[1]\n",
        "X_aug=np.ones((1,D))\n",
        "y_aug=np.ones(1)\n",
        "indexes=[]\n",
        "\n",
        "random.seed(0)\n",
        "for i in range(10000):\n",
        "    ind = random.randint(0,n)\n",
        "    indexes.append(ind)\n",
        "    y_aug=np.vstack((y_aug,y_real.iloc[ind]))\n",
        "    x = Xnp[ind,:]\n",
        "    x[:D-3]=x[:D-3]+np.random.normal(0,0.1,(D-3,))\n",
        "    X_aug=np.vstack((X_aug,x))\n",
        "X_aug=pd.DataFrame(X_aug[1:,:],columns=X.columns)\n",
        "y_aug=pd.DataFrame(y_aug[1:,:],columns=y_real.columns)\n",
        "\n",
        "X_new=pd.concat([X,X_aug])\n",
        "y_new=pd.concat([y_real,y_aug])\n",
        "\n",
        "X_new_future_only = X_new.drop(lst,axis=1)"
      ],
      "metadata": {
        "id": "g16-x8aPe7mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net=evaluateNN(months_scaled,X_new, X_new_future_only, y_new,y_scaled=True, scaler=sc_y_real, aug=True, X_original=X_future ,y_original=y_real)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByiOJfH3e7kH",
        "outputId": "f286cf74-7f16-42d2-a5c2-e37c66c99233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE_train FT [3336.38, 3075.01, 7717.0] avg: 4709.46\n",
            "MSE_test FT [624.65, 45145.49, 1107.73] avg: 15625.96\n",
            "MAE_train FT [18.27, 17.83, 19.75] avg: 18.62\n",
            "MAE_test FT [14.76, 36.96, 19.51] avg: 23.74\n",
            "MSE_pretrain_train PT [34.79, 21.51, 28.94] avg: 28.41\n",
            "MAE_pretrain_train PT [3.51, 2.91, 3.16] avg: 3.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net=evaluateNN(months_scaled,X_new, X_new_future_only, y_new,y_scaled=True, scaler=sc_y_real, aug=True, X_original=X_future ,y_original=y_real,unfreeze=True)\n",
        "# WOW- Representation Learning actually works!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYc5ZdMHjURo",
        "outputId": "c7d8c398-74e3-49be-a90e-1c9b0c6dbe8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE_train FT [60.79, 36.79, 54.04] avg: 50.54\n",
            "MSE_test FT [345.64, 3342.8, 175.16] avg: 1287.87\n",
            "MAE_train FT [4.58, 3.86, 4.63] avg: 4.36\n",
            "MAE_test FT [6.89, 9.1, 7.66] avg: 7.88\n",
            "MSE_pretrain_train PT [30.16, 21.81, 23.5] avg: 25.16\n",
            "MAE_pretrain_train PT [3.23, 2.93, 2.87] avg: 3.01\n"
          ]
        }
      ]
    }
  ]
}